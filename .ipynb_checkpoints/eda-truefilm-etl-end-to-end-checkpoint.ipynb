{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scope of the Notebook\n",
    "\n",
    "We want to extract the information from the csv and xml file. We also want to transform the data in the right format and do some simple aggregation. \n",
    "\n",
    "The transformed data will be loaded into a postgres database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Extract and Transform the .xml file from wikipedia "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. to extract the xml from the gz https://stackoverflow.com/questions/26577777/how-to-copy-and-extract-gz-files-using-python\n",
    "import gzip\n",
    "import glob\n",
    "import os.path\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "source_dir = str(Path().absolute())\n",
    "dest_dir = str(Path().absolute())\n",
    "# we generate a temp file before extrcting as a safeguard\n",
    "tmpfile = str(Path().absolute())+'tmp_file.xml'\n",
    "\n",
    "for src_name in glob.glob(os.path.join(source_dir, '*.gz')):\n",
    "    base = os.path.basename(src_name)\n",
    "    dest_name = os.path.join(dest_dir, base[:-3])\n",
    "    shutil.copyfile(src_name, tmpfile)\n",
    "    with gzip.open(tmpfile, 'rb') as infile:\n",
    "        with open(dest_name, 'wb') as outfile:\n",
    "            for line in infile:\n",
    "                outfile.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse XML into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.iditect.com/how-to/56888333.html\n",
    "from lxml import etree\n",
    "\n",
    "tree = etree.parse('enwiki-latest-abstract.xml')\n",
    "root = tree.getroot()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# let's have a look at the raw structure of the root element\n",
    "print(etree.tostring(root[0], pretty_print=True).decode(\"utf-8\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# here we can explore the root in a more structured way\n",
    "def explore_element(element):\n",
    "    print(element.tag)\n",
    "    print(element.attrib)\n",
    "    print(element.text)\n",
    "    for child in element:\n",
    "        explore_element(child)\n",
    "\n",
    "explore_element(root[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that the elements we are interested in are the element at 0, 1, and 2 respectively the title, the url and the abstract. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using simple for loop to extract info from the XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can access the XML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using lxml and findall "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can create a function that iterate over the xml root and create a list of the text contained in the element tag\n",
    "\n",
    "def text_extract(tag):\n",
    "    \"\"\"\n",
    "    Get the text contained within the specific tag\n",
    "    \n",
    "    input tag: string of tag present in the Element tree\n",
    "    \"\"\"\n",
    "    tmp_titles = []\n",
    "    \n",
    "    for title in root.findall('.//'+tag, namespaces=root.nsmap):\n",
    "        tmp_titles.append(title.text)\n",
    "    return tmp_titles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this lead to slow performance ~25-30min only for one element\n",
    "title_lst = text_extract('title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another approach could be the one to treat the xml as a tree of objects. We can construct a for loop to iterate over the different elements of the root and parse the content in a dictionary. This will then serve to create a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we need to understand how many element of interest we have. This takes ~ 14 min to run\n",
    "len(list(root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a quick look at the structure and we realize we can query the element directly\n",
    "display(root[0][0].text)\n",
    "display(root[0][1].text)\n",
    "display(root[0][2].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the following strucutre \n",
    "root --> element --> tag \n",
    "where the 1st tag is the title, the second tag is th url and the third tag is the abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize dictionary to store extraction over 10000 doens't finish\n",
    "data_dump = {}\n",
    "\n",
    "for i in range(0, 1000):\n",
    "    data_dump[root[i][0].text] = {\n",
    "        'url':root[i][1].text,\n",
    "        'abstract':root[i][2].text,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_dump)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this method doesn't lead to efficiency at the increase of the number of items. I decide to use the initial function using map, which is more efficient than a simple for loop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using map \n",
    "def append(title):\n",
    "    return title.text\n",
    "# ~ 15 min\n",
    "titles = list(map(append, root.findall('.//title', namespaces=root.nsmap)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~ 15 min\n",
    "urls = list(map(append, root.findall('.//url', namespaces=root.nsmap)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts = list(map(append, root.findall('.//abstract', namespaces=root.nsmap)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script for extracting all the data from the xml takes about 2 hours and 20 min with map. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia_dump_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia_dump_df['title'] = titles\n",
    "wikipedia_dump_df['abstract'] = abstracts\n",
    "wikipedia_dump_df['url'] = urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia_dump_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia_dump_df.to_csv('wikipedia_dump.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean xml dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the wikipedia pattern from the title string\n",
    "wikipedia_dump_df['title'] = wikipedia_dump_df['title'].map(lambda x: x.lstrip('Wikipedia: '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # lower string title\n",
    "# wikipedia_dump_df['title'] = wikipedia_dump_df.title.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # lower string title\n",
    "# wikipedia_dump_df['title_squeeze'] = wikipedia_dump_df.title.str.replace(' ', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check duplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia_dump_df.groupby('title')['title'].count().sort_values(ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We realize that we might find ourselves with multiple entries of the same title. This could create problems down the line. \n",
    "\n",
    "**Assumption** we might need to keep the titles as they are. Since we are going to match the titles of wikipedia articles with the titles of the movies, we might need to maintain the Upper/lower cases and spaces to match the movie titles. In fact, we realize that the wikipedia dump might contain a mix of words, thus we might achieve a more specific join using the non-transformed titles. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia_dump_df[(wikipedia_dump_df['title'] == 'Life') | (wikipedia_dump_df['title'] == 'Red') | (wikipedia_dump_df['title'] == 'Ali') | (wikipedia_dump_df['title'] == 'The Kingdom') ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that the duplication may come from cases where the title is ambiguous. In those cases, we can have multiple abstracts and urls indicating different options. At this stage, we don't have a good way to quickly reconcile these cases. \n",
    "\n",
    "A potential solution could be to further explore the XML file to understand wether there are anchors available to select only movie pages. \n",
    "\n",
    "Alternatively, we could search the abstract of these cases for hints suggesting movies (e.g. the string contains the word movie).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manfredimiraula/.virtualenvs/projects/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "media_csv = pd.read_csv('movies_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adult</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>...</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>video</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 10194, 'name': 'Toy Story Collection', ...</td>\n",
       "      <td>30000000</td>\n",
       "      <td>[{'id': 16, 'name': 'Animation'}, {'id': 35, '...</td>\n",
       "      <td>http://toystory.disney.com/toy-story</td>\n",
       "      <td>862</td>\n",
       "      <td>tt0114709</td>\n",
       "      <td>en</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-10-30</td>\n",
       "      <td>373554033.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>False</td>\n",
       "      <td>7.7</td>\n",
       "      <td>5415.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65000000</td>\n",
       "      <td>[{'id': 12, 'name': 'Adventure'}, {'id': 14, '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8844</td>\n",
       "      <td>tt0113497</td>\n",
       "      <td>en</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-12-15</td>\n",
       "      <td>262797249.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}, {'iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Roll the dice and unleash the excitement!</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>False</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2413.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   adult                              belongs_to_collection    budget  \\\n",
       "0  False  {'id': 10194, 'name': 'Toy Story Collection', ...  30000000   \n",
       "1  False                                                NaN  65000000   \n",
       "\n",
       "                                              genres  \\\n",
       "0  [{'id': 16, 'name': 'Animation'}, {'id': 35, '...   \n",
       "1  [{'id': 12, 'name': 'Adventure'}, {'id': 14, '...   \n",
       "\n",
       "                               homepage    id    imdb_id original_language  \\\n",
       "0  http://toystory.disney.com/toy-story   862  tt0114709                en   \n",
       "1                                   NaN  8844  tt0113497                en   \n",
       "\n",
       "  original_title                                           overview  ...  \\\n",
       "0      Toy Story  Led by Woody, Andy's toys live happily in his ...  ...   \n",
       "1        Jumanji  When siblings Judy and Peter discover an encha...  ...   \n",
       "\n",
       "  release_date      revenue runtime  \\\n",
       "0   1995-10-30  373554033.0    81.0   \n",
       "1   1995-12-15  262797249.0   104.0   \n",
       "\n",
       "                                    spoken_languages    status  \\\n",
       "0           [{'iso_639_1': 'en', 'name': 'English'}]  Released   \n",
       "1  [{'iso_639_1': 'en', 'name': 'English'}, {'iso...  Released   \n",
       "\n",
       "                                     tagline      title  video vote_average  \\\n",
       "0                                        NaN  Toy Story  False          7.7   \n",
       "1  Roll the dice and unleash the excitement!    Jumanji  False          6.9   \n",
       "\n",
       "  vote_count  \n",
       "0     5415.0  \n",
       "1     2413.0  \n",
       "\n",
       "[2 rows x 24 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "media_csv.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45466 entries, 0 to 45465\n",
      "Data columns (total 24 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   adult                  45466 non-null  object \n",
      " 1   belongs_to_collection  4494 non-null   object \n",
      " 2   budget                 45466 non-null  object \n",
      " 3   genres                 45466 non-null  object \n",
      " 4   homepage               7782 non-null   object \n",
      " 5   id                     45466 non-null  object \n",
      " 6   imdb_id                45449 non-null  object \n",
      " 7   original_language      45455 non-null  object \n",
      " 8   original_title         45466 non-null  object \n",
      " 9   overview               44512 non-null  object \n",
      " 10  popularity             45461 non-null  object \n",
      " 11  poster_path            45080 non-null  object \n",
      " 12  production_companies   45463 non-null  object \n",
      " 13  production_countries   45463 non-null  object \n",
      " 14  release_date           45379 non-null  object \n",
      " 15  revenue                45460 non-null  float64\n",
      " 16  runtime                45203 non-null  float64\n",
      " 17  spoken_languages       45460 non-null  object \n",
      " 18  status                 45379 non-null  object \n",
      " 19  tagline                20412 non-null  object \n",
      " 20  title                  45460 non-null  object \n",
      " 21  video                  45460 non-null  object \n",
      " 22  vote_average           45460 non-null  float64\n",
      " 23  vote_count             45460 non-null  float64\n",
      "dtypes: float64(4), object(20)\n",
      "memory usage: 8.3+ MB\n"
     ]
    }
   ],
   "source": [
    "media_csv.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some missing data in the dataset. In particular, we notice that we have 6 films with no revenue, no title. 87 films don't have a release_date and only 3 films don't have a production companies. \n",
    "\n",
    "Also in this case, we want to keep the titles as they are to perfrom a specific match with the wikipedia articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # lower string case in original title\n",
    "# media_csv['original_title'] = media_csv.original_title.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # lower string case in original title\n",
    "# media_csv['title_squeeze'] = media_csv.original_title.str.replace(' ', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_title</th>\n",
       "      <th>title</th>\n",
       "      <th>revenue</th>\n",
       "      <th>production_companies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19729</th>\n",
       "      <td>Midnight Man</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19730</th>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29502</th>\n",
       "      <td>マルドゥック・スクランブル 排気</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29503</th>\n",
       "      <td>[{'iso_639_1': 'ja', 'name': '日本語'}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35586</th>\n",
       "      <td>Avalanche Sharks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35587</th>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 original_title title  revenue  \\\n",
       "19729                              Midnight Man   NaN      NaN   \n",
       "19730  [{'iso_639_1': 'en', 'name': 'English'}]   NaN      NaN   \n",
       "29502                          マルドゥック・スクランブル 排気   NaN      NaN   \n",
       "29503      [{'iso_639_1': 'ja', 'name': '日本語'}]   NaN      NaN   \n",
       "35586                          Avalanche Sharks   NaN      NaN   \n",
       "35587  [{'iso_639_1': 'en', 'name': 'English'}]   NaN      NaN   \n",
       "\n",
       "      production_companies  \n",
       "19729                  NaN  \n",
       "19730                False  \n",
       "29502                  NaN  \n",
       "29503                False  \n",
       "35586                  NaN  \n",
       "35587                False  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "media_csv[media_csv['title'].isnull()][['original_title', 'title', 'revenue', 'production_companies']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the entries without a title, we notice that some of these have non-standard characters (Japanese) and some seem to have not a movie title. In future iteration, we should consider the handlling of movies with non-standard characters. However, for the purpose of this script, we can use the colum \"original_title\" as the key to join with the wikipedia dataset. These movies are also the ones with no revenue or production companies. \n",
    "\n",
    "At this stage, we decide not to evaluate any method for imputing the missing value as further understanding of the data and additional context would be needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adult</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>...</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>video</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>365371</td>\n",
       "      <td>tt0114894</td>\n",
       "      <td>en</td>\n",
       "      <td>War Stories Our Mother Never Told Us</td>\n",
       "      <td>Seven New Zealand women speak about their live...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>War Stories Our Mother Never Told Us</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>215107</td>\n",
       "      <td>tt0105737</td>\n",
       "      <td>en</td>\n",
       "      <td>Vermont Is for Lovers</td>\n",
       "      <td>Vermont is for Lovers is an independently prod...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vermont Is for Lovers</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3460</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'id': 18, 'name': 'Drama'}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94214</td>\n",
       "      <td>tt0210130</td>\n",
       "      <td>en</td>\n",
       "      <td>Jails, Hospitals &amp; Hip-Hop</td>\n",
       "      <td>Jails, Hospitals &amp;amp; Hip-Hop is a cinematic ...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>three worlds / two million voices / one genera...</td>\n",
       "      <td>Jails, Hospitals &amp; Hip-Hop</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3628</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>207731</td>\n",
       "      <td>tt0217287</td>\n",
       "      <td>en</td>\n",
       "      <td>Boricua's Bond</td>\n",
       "      <td>Tommy, a talented Puerto Rican painter living ...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Boricua's Bond</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5879</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'id': 18, 'name': 'Drama'}, {'id': 10749, 'n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99885</td>\n",
       "      <td>tt0979876</td>\n",
       "      <td>en</td>\n",
       "      <td>Divine Intervention</td>\n",
       "      <td>Four friends fight an insane man's crusade to ...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>Released</td>\n",
       "      <td>His Judgement Cometh...</td>\n",
       "      <td>Divine Intervention</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45148</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>438910</td>\n",
       "      <td>tt0810384</td>\n",
       "      <td>ru</td>\n",
       "      <td>Konstruktor krasnogo tsveta -1993</td>\n",
       "      <td>Engineering Red - 1993  Dir: Andrey I. Y. Petr...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Engineering Red</td>\n",
       "      <td>False</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45203</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'id': 9648, 'name': 'Mystery'}, {'id': 878, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>433711</td>\n",
       "      <td>tt3158690</td>\n",
       "      <td>en</td>\n",
       "      <td>All Superheroes Must Die 2: The Last Superhero</td>\n",
       "      <td>In a no holds barred documentary, acclaimed jo...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All Superheroes Must Die 2: The Last Superhero</td>\n",
       "      <td>False</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45338</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>335251</td>\n",
       "      <td>tt1883368</td>\n",
       "      <td>en</td>\n",
       "      <td>The Land Where the Blues Began</td>\n",
       "      <td>An exploration of the musical and social origi...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Land Where the Blues Began</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45410</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'id': 18, 'name': 'Drama'}, {'id': 80, 'name...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>449131</td>\n",
       "      <td>tt0321264</td>\n",
       "      <td>ru</td>\n",
       "      <td>Aprel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aprel</td>\n",
       "      <td>False</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45461</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'id': 18, 'name': 'Drama'}, {'id': 10751, 'n...</td>\n",
       "      <td>http://www.imdb.com/title/tt6209470/</td>\n",
       "      <td>439050</td>\n",
       "      <td>tt6209470</td>\n",
       "      <td>fa</td>\n",
       "      <td>رگ خواب</td>\n",
       "      <td>Rising and falling between a man and woman.</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>[{'iso_639_1': 'fa', 'name': 'فارسی'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Rising and falling between a man and woman</td>\n",
       "      <td>Subdue</td>\n",
       "      <td>False</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       adult belongs_to_collection budget  \\\n",
       "711    False                   NaN      0   \n",
       "734    False                   NaN      0   \n",
       "3460   False                   NaN      0   \n",
       "3628   False                   NaN      0   \n",
       "5879   False                   NaN      0   \n",
       "...      ...                   ...    ...   \n",
       "45148  False                   NaN      0   \n",
       "45203  False                   NaN      0   \n",
       "45338  False                   NaN      0   \n",
       "45410  False                   NaN      0   \n",
       "45461  False                   NaN      0   \n",
       "\n",
       "                                                  genres  \\\n",
       "711                                                   []   \n",
       "734                                                   []   \n",
       "3460                       [{'id': 18, 'name': 'Drama'}]   \n",
       "3628                                                  []   \n",
       "5879   [{'id': 18, 'name': 'Drama'}, {'id': 10749, 'n...   \n",
       "...                                                  ...   \n",
       "45148                                                 []   \n",
       "45203  [{'id': 9648, 'name': 'Mystery'}, {'id': 878, ...   \n",
       "45338                                                 []   \n",
       "45410  [{'id': 18, 'name': 'Drama'}, {'id': 80, 'name...   \n",
       "45461  [{'id': 18, 'name': 'Drama'}, {'id': 10751, 'n...   \n",
       "\n",
       "                                   homepage      id    imdb_id  \\\n",
       "711                                     NaN  365371  tt0114894   \n",
       "734                                     NaN  215107  tt0105737   \n",
       "3460                                    NaN   94214  tt0210130   \n",
       "3628                                    NaN  207731  tt0217287   \n",
       "5879                                    NaN   99885  tt0979876   \n",
       "...                                     ...     ...        ...   \n",
       "45148                                   NaN  438910  tt0810384   \n",
       "45203                                   NaN  433711  tt3158690   \n",
       "45338                                   NaN  335251  tt1883368   \n",
       "45410                                   NaN  449131  tt0321264   \n",
       "45461  http://www.imdb.com/title/tt6209470/  439050  tt6209470   \n",
       "\n",
       "      original_language                                  original_title  \\\n",
       "711                  en            War Stories Our Mother Never Told Us   \n",
       "734                  en                           Vermont Is for Lovers   \n",
       "3460                 en                      Jails, Hospitals & Hip-Hop   \n",
       "3628                 en                                  Boricua's Bond   \n",
       "5879                 en                             Divine Intervention   \n",
       "...                 ...                                             ...   \n",
       "45148                ru               Konstruktor krasnogo tsveta -1993   \n",
       "45203                en  All Superheroes Must Die 2: The Last Superhero   \n",
       "45338                en                  The Land Where the Blues Began   \n",
       "45410                ru                                           Aprel   \n",
       "45461                fa                                         رگ خواب   \n",
       "\n",
       "                                                overview  ... release_date  \\\n",
       "711    Seven New Zealand women speak about their live...  ...          NaN   \n",
       "734    Vermont is for Lovers is an independently prod...  ...          NaN   \n",
       "3460   Jails, Hospitals &amp; Hip-Hop is a cinematic ...  ...          NaN   \n",
       "3628   Tommy, a talented Puerto Rican painter living ...  ...          NaN   \n",
       "5879   Four friends fight an insane man's crusade to ...  ...          NaN   \n",
       "...                                                  ...  ...          ...   \n",
       "45148  Engineering Red - 1993  Dir: Andrey I. Y. Petr...  ...          NaN   \n",
       "45203  In a no holds barred documentary, acclaimed jo...  ...          NaN   \n",
       "45338  An exploration of the musical and social origi...  ...          NaN   \n",
       "45410                                                NaN  ...          NaN   \n",
       "45461        Rising and falling between a man and woman.  ...          NaN   \n",
       "\n",
       "      revenue runtime                          spoken_languages    status  \\\n",
       "711       0.0    95.0                                        []  Released   \n",
       "734       0.0    88.0                                        []  Released   \n",
       "3460     10.0    90.0                                        []       NaN   \n",
       "3628      0.0   105.0                                        []  Released   \n",
       "5879      0.0    87.0                                        []  Released   \n",
       "...       ...     ...                                       ...       ...   \n",
       "45148     0.0    76.0                                        []  Released   \n",
       "45203     0.0    74.0  [{'iso_639_1': 'en', 'name': 'English'}]  Released   \n",
       "45338     0.0     0.0                                        []  Released   \n",
       "45410     0.0     NaN                                        []  Released   \n",
       "45461     0.0    90.0    [{'iso_639_1': 'fa', 'name': 'فارسی'}]  Released   \n",
       "\n",
       "                                                 tagline  \\\n",
       "711                                                  NaN   \n",
       "734                                                  NaN   \n",
       "3460   three worlds / two million voices / one genera...   \n",
       "3628                                                 NaN   \n",
       "5879                             His Judgement Cometh...   \n",
       "...                                                  ...   \n",
       "45148                                                NaN   \n",
       "45203                                                NaN   \n",
       "45338                                                NaN   \n",
       "45410                                                NaN   \n",
       "45461         Rising and falling between a man and woman   \n",
       "\n",
       "                                                title  video vote_average  \\\n",
       "711              War Stories Our Mother Never Told Us  False          0.0   \n",
       "734                             Vermont Is for Lovers  False          0.0   \n",
       "3460                       Jails, Hospitals & Hip-Hop  False          0.0   \n",
       "3628                                   Boricua's Bond  False          2.0   \n",
       "5879                              Divine Intervention  False          0.0   \n",
       "...                                               ...    ...          ...   \n",
       "45148                                 Engineering Red  False          6.0   \n",
       "45203  All Superheroes Must Die 2: The Last Superhero  False          4.0   \n",
       "45338                  The Land Where the Blues Began  False          0.0   \n",
       "45410                                           Aprel  False          6.0   \n",
       "45461                                          Subdue  False          4.0   \n",
       "\n",
       "      vote_count  \n",
       "711          0.0  \n",
       "734          0.0  \n",
       "3460         0.0  \n",
       "3628         1.0  \n",
       "5879         0.0  \n",
       "...          ...  \n",
       "45148        2.0  \n",
       "45203        1.0  \n",
       "45338        0.0  \n",
       "45410        1.0  \n",
       "45461        1.0  \n",
       "\n",
       "[87 rows x 24 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "media_csv[media_csv['release_date'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can't evaluate any peculiar pattern at first glance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling budget and revenue column\n",
    "We notice that the budget column possess mixed data types. Additionally, we realize that a number of budget columns contain a vlaue of zero (or they are Null). \n",
    "\n",
    "Without additional investigation or context, is hard to impute these columns and, at the same time, we don't want to carry them as it will impact the value of the ratio giving infinite values which cannot be sorted properly. We decide to drop these columns. \n",
    "\n",
    "We also notice that we have a number of columns which have a very low budget and revenue. For example the title Karate Kid part 2 has a budget of 113. This is probably an incorrect imputation of the budget. It would make sense for it to be 113,000 as it is expected that a move production is very costly. However, we don't have a good way at this stage to impute this value. At the same time, if we carry over this rows we might have imprecise consideration on the calculation of the ratio. For this reason, we decide to only carry over those rows for which the budget and revenue is higher than the median budget of the movies we have at our disposal. We select the median value so that we can limit the effect of outliers. We could have used the 25th percentile instead, to carry more entries.\n",
    "\n",
    "These columns account for 2.8K+ (or ~2% of our dataset). For sure this is something we would want to improve down the line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "media_df = media_csv.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adult</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>...</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>video</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19730</th>\n",
       "      <td>- Written by Ørnås</td>\n",
       "      <td>0.065736</td>\n",
       "      <td>/ff9qCepilowshEtG2GYWwzt2bs4.jpg</td>\n",
       "      <td>[{'name': 'Carousel Productions', 'id': 11176}...</td>\n",
       "      <td>[{'iso_3166_1': 'CA', 'name': 'Canada'}, {'iso...</td>\n",
       "      <td>1997-08-20</td>\n",
       "      <td>0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     adult belongs_to_collection  \\\n",
       "19730   - Written by Ørnås              0.065736   \n",
       "\n",
       "                                 budget  \\\n",
       "19730  /ff9qCepilowshEtG2GYWwzt2bs4.jpg   \n",
       "\n",
       "                                                  genres  \\\n",
       "19730  [{'name': 'Carousel Productions', 'id': 11176}...   \n",
       "\n",
       "                                                homepage          id imdb_id  \\\n",
       "19730  [{'iso_3166_1': 'CA', 'name': 'Canada'}, {'iso...  1997-08-20       0   \n",
       "\n",
       "      original_language                            original_title  overview  \\\n",
       "19730             104.0  [{'iso_639_1': 'en', 'name': 'English'}]  Released   \n",
       "\n",
       "       ... release_date revenue runtime spoken_languages status  tagline  \\\n",
       "19730  ...            1     NaN     NaN              NaN    NaN      NaN   \n",
       "\n",
       "       title video vote_average vote_count  \n",
       "19730    NaN   NaN          NaN        NaN  \n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of column with a mixed type\n",
    "media_df[media_df['budget'] == '/ff9qCepilowshEtG2GYWwzt2bs4.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the column values with text in integer \n",
    "mask = media_df[media_df['budget'].str.isnumeric() == False].index\n",
    "media_df.loc[mask,'budget'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adult</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>...</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>video</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [adult, belongs_to_collection, budget, genres, homepage, id, imdb_id, original_language, original_title, overview, popularity, poster_path, production_companies, production_countries, release_date, revenue, runtime, spoken_languages, status, tagline, title, video, vote_average, vote_count]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 24 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "media_df[media_df['budget'] == '/ff9qCepilowshEtG2GYWwzt2bs4.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "media_df['budget'] = media_df['budget'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median revenue is: 16822718.5\n",
      "25th percentile is: 2400000.0\n"
     ]
    }
   ],
   "source": [
    "# evaluate the revenue column. We have some values that are zero but others that have very low revenue\n",
    "print('Median revenue is: ' + str(media_df[media_df['revenue'] > 0]['revenue'].median()))\n",
    "print('25th percentile is: ' + str(media_df[media_df['revenue'] > 0]['revenue'].quantile(q = 0.25)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median budget is: 8000000.0\n",
      "25th percentile is: 2000000.0\n"
     ]
    }
   ],
   "source": [
    "# evaluate the revenue column. We have some values that are zero but others that have very low budget\n",
    "print('Median budget is: ' + str(media_df[media_df['budget'] > 0]['budget'].median()))\n",
    "print('25th percentile is: ' + str(media_df[media_df['budget'] > 0]['budget'].quantile(q = 0.25)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2855"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we check the amount of entries we carry over by applying these masks\n",
    "media_df[(media_df['budget'] >= 8000000) & (media_df['revenue'] > 16822718.5)]['title'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "media_df = media_df[(media_df['budget'] >= 8000000) & (media_df['revenue'] > 16822718.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create the ratio column\n",
    "media_df['ratio'] = media_df['budget']/media_df['revenue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have no column named \"rating\". However, we can observe a column popularity. We take this as a rating value\n",
    "media_df = media_df[['original_title', 'title', 'budget', 'release_date', 'revenue', 'ratio','popularity', 'production_companies']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [{'name': 'Pixar Animation Studios', 'id': 3}]\n",
       "1     [{'name': 'TriStar Pictures', 'id': 559}, {'na...\n",
       "3     [{'name': 'Twentieth Century Fox Film Corporat...\n",
       "5     [{'name': 'Regency Enterprises', 'id': 508}, {...\n",
       "8     [{'name': 'Universal Pictures', 'id': 33}, {'n...\n",
       "9     [{'name': 'United Artists', 'id': 60}, {'name'...\n",
       "10    [{'name': 'Columbia Pictures', 'id': 5}, {'nam...\n",
       "15    [{'name': 'Universal Pictures', 'id': 33}, {'n...\n",
       "16    [{'name': 'Columbia Pictures Corporation', 'id...\n",
       "18    [{'name': 'O Entertainment', 'id': 5682}, {'na...\n",
       "Name: production_companies, dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "media_df.production_companies.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have noticed that the production_companies column contains a json-like string. We decide to not transform this column at this stage. However, an option could be to expand the json so that, for movies with multiple production companies, we obtain one column for each company. However, additional information on the final goal of this data would be needed to make this decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we try to convert the popularity column to a float we obtain an error related to a mixed composition of float and strings. We can convert the string values to NaN using some pandas functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adult</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>...</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>video</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35587</th>\n",
       "      <td>Avalanche Sharks tells the story of a bikini ...</td>\n",
       "      <td>2.185485</td>\n",
       "      <td>/zaSf5OG7V8X8gqFvly88zDdRm46.jpg</td>\n",
       "      <td>[{'name': 'Odyssey Media', 'id': 17161}, {'nam...</td>\n",
       "      <td>[{'iso_3166_1': 'CA', 'name': 'Canada'}]</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   adult  \\\n",
       "35587   Avalanche Sharks tells the story of a bikini ...   \n",
       "\n",
       "      belongs_to_collection                            budget  \\\n",
       "35587              2.185485  /zaSf5OG7V8X8gqFvly88zDdRm46.jpg   \n",
       "\n",
       "                                                  genres  \\\n",
       "35587  [{'name': 'Odyssey Media', 'id': 17161}, {'nam...   \n",
       "\n",
       "                                       homepage          id imdb_id  \\\n",
       "35587  [{'iso_3166_1': 'CA', 'name': 'Canada'}]  2014-01-01       0   \n",
       "\n",
       "      original_language                            original_title  overview  \\\n",
       "35587              82.0  [{'iso_639_1': 'en', 'name': 'English'}]  Released   \n",
       "\n",
       "       ... release_date revenue runtime spoken_languages status  tagline  \\\n",
       "35587  ...           22     NaN     NaN              NaN    NaN      NaN   \n",
       "\n",
       "       title video vote_average vote_count  \n",
       "35587    NaN   NaN          NaN        NaN  \n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform the populatity column into a float type\n",
    "media_csv[media_csv['popularity'] == 'Beware Of Frost Bites']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "media_csv['popularity'] = pd.to_numeric(media_csv['popularity'],errors='coerce').astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for duplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "media_df.groupby('original_title')['original_title'].count().sort_values(ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "media_df[(media_df['title'] == 'Beauty and the Beast')|(media_df['title'] == 'Clockstoppers')|(media_df['title'] == 'Life')|(media_df['title'] == 'The Manchurian Candidate')|(media_df['title'] == 'The Three Musketeers')].sort_values('original_title')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the duplicates have multiple popularity ratings. Without additional context, we will select those titles with the higher popularity score. We should be mindful that we don't remove cases where the title is the same but the movie is different (e.g. older, more recent version of the movie like Beauty And The Beast). In these cases, we will use the release date to understand wether the movie is the same or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only the duplicates where the release_date is different\n",
    "media_df = media_df.drop_duplicates(subset=['release_date','title'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order by the ratio value and take the first 1000 entries\n",
    "media_df = media_df.sort_values('ratio', ascending = False).head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "media_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "media_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the csv for backup\n",
    "media_df.to_csv('media_df.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left merge to join the two dataset\n",
    "temp = media_df.merge(wikipedia_dump_df, how = 'left', on = 'title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = temp[['title', 'budget', 'release_date', 'revenue', 'ratio','popularity', 'production_companies', 'abstract', 'url']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.rename(columns = {\n",
    "    'original_title':'title', \n",
    "    'optimized_budget':'budget', \n",
    "    'release_date': 'year', \n",
    "    'popularity':'rating', \n",
    "    'production_companies': 'production_company'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We weren't able to match all the 1000 titles with the wikipedia match. This might be do to a mismatch at the level of the title or due to the incompleteness of the wikipedia dump. \n",
    "\n",
    "A google search allowed me to understand that the wikipedia dump is not always relaiable and may not contain all the indexed pages. It seems reasonable that we are able to partially match the 1000 title. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('pre-load-df.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the Postgres database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a connection with the database\n",
    "try:\n",
    "    conn = psycopg2.connect(database = \"postgres\", user = \"truer\", password = \"filmaker\", host = \"localhost\", port = \"5432\")\n",
    "except:\n",
    "    print(\"I am unable to connect to the database\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql+psycopg2://{}:{}@{}:{}/postgres' \\\n",
    "    .format('truer', # username\n",
    "            'filmaker', # password\n",
    "            'localhost', # host\n",
    "            '5432' # local port\n",
    "           ) \n",
    "    , echo=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we want to have created the postgres database. We will have to do this via the command line\n",
    "Installation/setup\n",
    "- Install Homebrew\n",
    "    - How to\n",
    "- Install postgresql\n",
    "- pg_ctl -D /usr/local/var/postgres start && brew services start postgresql (if you want to make sure that postgres starts at computer start)\n",
    "- validate correct installation using postgres -V\n",
    "\n",
    "Start postgres via terminal and initialize the database \n",
    "- psql postgres\n",
    "    - if you encounter the following error \"could not connect to server: No such file or directory\n",
    "        Is the server running locally and accepting\n",
    "        connections on Unix domain socket \"/tmp/.s.PGSQL.5432\"?\" try to run:\n",
    "        - $ rm /usr/local/var/postgres/postmaster.pid\n",
    "        - $ brew services restart postgresql\n",
    "- if everything went correctly, you should see the postgres database in terminal accepting commands\n",
    "- now we need to create our user and access to the database. Postgres automatically create a user when we initialize the DB, but since I won't be controlling it, in order to automate the process I specific user and passowrd so that I'm sure we can specify the same in the following script to import the data\n",
    "- run CREATE ROLE truer  WITH LOGIN PASSWORD 'filmaker'; --> this will create the role with password\n",
    "- run ALTER ROLE truer  CREATEDB; --> this will allow the user we just created to create and modify the database\n",
    "- run \\du to check that the role is present with the correct permission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = conn.cursor()\n",
    "try:\n",
    "    cur.execute(\"\"\"\n",
    "    DROP TABLE IF EXISTS true_film;\n",
    "    CREATE TABLE IF NOT EXISTS true_film\n",
    "\t(\n",
    "        id SERIAL NOT NULL, \n",
    "        \n",
    "        title varchar(255),\n",
    "        \n",
    "        budget bigint,\n",
    "\n",
    "\t\tyear date,\n",
    "        \n",
    "        revenue numeric, \n",
    "        \n",
    "        ratio numeric, \n",
    "        \n",
    "        rating numeric, \n",
    "\n",
    "        production_company text,\n",
    "        \n",
    "        abstract text,\n",
    "        \n",
    "        url varchar(255), \n",
    "\n",
    "\t\tcreated_at timestamp without time zone NOT NULL DEFAULT NOW(),\n",
    "    \tupdated_at timestamp without time zone DEFAULT NULL,\n",
    "    \tCONSTRAINT true_film_key PRIMARY KEY (id)\n",
    "\n",
    "\t\t)\n",
    "\tWITH (\n",
    "    OIDS = FALSE\n",
    ")\n",
    "TABLESPACE pg_default;\n",
    "\n",
    "ALTER TABLE true_film\n",
    "    OWNER to truer;\n",
    "\n",
    "CREATE INDEX true_film_title ON true_film(title, production_company, ratio, revenue);\"\"\")\n",
    "except:\n",
    "    print(\"I can't drop our test database!\")\n",
    "\n",
    "conn.commit() # <--- makes sure the change is shown in the database\n",
    "conn.close()\n",
    "cur.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify that the table has been created\n",
    "engine.execute(\"\"\"\n",
    "SELECT * FROM true_film;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_sql('true_film', engine, if_exists = 'append', index = False,\n",
    "               chunksize = 1000, method = 'multi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
